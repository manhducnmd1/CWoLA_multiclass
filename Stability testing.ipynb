{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74721ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 09:15:44.207494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2024-12-26 09:15:47.470537: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-26 09:15:47.470595: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ubuntu\n",
      "2024-12-26 09:15:47.470601: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ubuntu\n",
      "2024-12-26 09:15:47.470853: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.182.3\n",
      "2024-12-26 09:15:47.470883: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.182.3\n",
      "2024-12-26 09:15:47.470887: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.182.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from scipy import interpolate\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import ternary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '012'\n",
    "from tensorflow.python.client import device_lib\n",
    "physical_gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306e3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86bab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(32, input_dim=input_dim, activation='relu'))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-2),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973ba5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_clustering(input_dim):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(16, input_dim=input_dim, activation='relu'))\n",
    "    model.add(keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-2),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecc1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repertoire 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 09:17:30.787675: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2024-12-26 09:17:30.816384: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200000000 Hz\n",
      "2024-12-26 09:17:30.818802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558ce7944850 executing computations on platform Host. Devices:\n",
      "2024-12-26 09:17:30.819232: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "ml_total_accuracy = []\n",
    "spec_total_accuracy = []\n",
    "max_total_accuracy = []\n",
    "for i in range(10):\n",
    "    print(f\"Repertoire {i}\")\n",
    "    mean_1 = [0, 0, 0, 0, 0]\n",
    "    cov_1 = [[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1,0], [0, 0, 0, 0, 1]]\n",
    "\n",
    "    mean_2 = [1, 1, 1, 1, 1]\n",
    "    cov_2 = [[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1,0], [0, 0, 0, 0, 1]]\n",
    "\n",
    "    mean_3 = [-1, -1, -1, -1, -1]\n",
    "    cov_3 = [[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1,0], [0, 0, 0, 0, 1]]\n",
    "\n",
    "\n",
    "    x_1 = np.random.multivariate_normal(mean_1, cov_1, size=1000000)\n",
    "    y_1 = np.random.multivariate_normal(mean_1, cov_1, size=100000)\n",
    "\n",
    "    x_2 = np.random.multivariate_normal(mean_2, cov_2, size=1000000)\n",
    "    y_2 = np.random.multivariate_normal(mean_2, cov_2, size=100000)\n",
    "\n",
    "    x_3 = np.random.multivariate_normal(mean_3, cov_3, size=1000000)\n",
    "    y_3 = np.random.multivariate_normal(mean_3, cov_3, size=100000)\n",
    "    \n",
    "    x_kmeans_1 =  np.random.multivariate_normal(mean_1, cov_1, size=1000)\n",
    "    x_kmeans_2 =  np.random.multivariate_normal(mean_2, cov_2, size=1000)\n",
    "    x_kmeans_3 =  np.random.multivariate_normal(mean_3, cov_3, size=1000)\n",
    "    rng = np.random.default_rng()\n",
    "    x_train_kmeans = np.concatenate((x_kmeans_1, x_kmeans_2, x_kmeans_3))\n",
    "    indices_kmeans = rng.permutation(np.shape(x_train_kmeans)[0])\n",
    "    x_train_kmeans = x_train_kmeans[indices_kmeans]\n",
    "    \n",
    "    n_samples = 3\n",
    "    n_1_1 = 80000 #Number of signal samples in dominant class\n",
    "    n_1_2 = 10000\n",
    "    n_1_3 = 10000\n",
    "\n",
    "    n_2_1 = 70000\n",
    "    n_2_2 = 20000\n",
    "    n_2_3 = 10000\n",
    "\n",
    "    n_3_1 = 60000\n",
    "    n_3_2 = 25000\n",
    "    n_3_3 = 15000\n",
    "\n",
    "    sample_1_1_train = x_1[0:n_1_1]\n",
    "    #Using one-hot encoding here\n",
    "    true_label_sample_1_1_train = np.tile(np.array([1., 0., 0.]), \n",
    "                                          np.shape(sample_1_1_train)[0]).reshape(np.shape(sample_1_1_train)[0],n_samples)\n",
    "\n",
    "    sample_1_2_train = x_2[0:n_1_2]\n",
    "    true_label_sample_1_2_train = np.tile(np.array([0., 1., 0.]), \n",
    "                                          np.shape(sample_1_2_train)[0]).reshape(np.shape(sample_1_2_train)[0],n_samples)\n",
    "    sample_1_3_train = x_3[0:n_1_3]\n",
    "    true_label_sample_1_3_train = np.tile(np.array([0., 0., 1.]), \n",
    "                                          np.shape(sample_1_3_train)[0]).reshape(np.shape(sample_1_3_train)[0],n_samples)\n",
    "\n",
    "    sample_2_1_train = x_1[n_1_1:n_1_1+n_2_1]\n",
    "    #Using one-hot encoding here\n",
    "    true_label_sample_2_1_train = np.tile(np.array([1., 0., 0.]), \n",
    "                                          np.shape(sample_2_1_train)[0]).reshape(np.shape(sample_2_1_train)[0],n_samples)\n",
    "\n",
    "    sample_2_2_train = x_2[n_1_2:n_1_2 + n_2_2]\n",
    "    true_label_sample_2_2_train = np.tile(np.array([0., 1., 0.]), \n",
    "                                          np.shape(sample_2_2_train)[0]).reshape(np.shape(sample_2_2_train)[0],n_samples)\n",
    "    sample_2_3_train = x_3[n_1_3:n_1_3+n_2_3]\n",
    "    true_label_sample_2_3_train = np.tile(np.array([0., 0., 1.]), \n",
    "                                          np.shape(sample_2_3_train)[0]).reshape(np.shape(sample_2_3_train)[0],n_samples)\n",
    "\n",
    "    sample_3_1_train = x_1[n_1_1+n_2_1:n_1_1+n_2_1+n_3_1]\n",
    "    #Using one-hot encoding here\n",
    "    true_label_sample_3_1_train = np.tile(np.array([1., 0., 0.]), \n",
    "                                          np.shape(sample_3_1_train)[0]).reshape(np.shape(sample_3_1_train)[0],n_samples)\n",
    "\n",
    "    sample_3_2_train = x_2[n_1_2+n_2_2:n_1_2+n_2_2+n_3_2]\n",
    "    true_label_sample_3_2_train = np.tile(np.array([0., 1., 0.]), \n",
    "                                          np.shape(sample_3_2_train)[0]).reshape(np.shape(sample_3_2_train)[0],n_samples)\n",
    "    sample_3_3_train = x_3[n_1_3+n_2_3:n_1_3+n_2_3+n_3_3]\n",
    "    true_label_sample_3_3_train = np.tile(np.array([0., 0., 1.]), \n",
    "                                          np.shape(sample_3_3_train)[0]).reshape(np.shape(sample_3_3_train)[0],n_samples)\n",
    "    \n",
    "    x_test = np.concatenate((y_1, y_2, y_3))\n",
    "    y_test_1 = np.tile(np.array([1., 0., 0.]), \n",
    "                np.shape(y_1)[0]).reshape(np.shape(y_1)[0],n_samples)\n",
    "    y_test_2 = np.tile(np.array([0., 1., 0.]), \n",
    "                np.shape(y_2)[0]).reshape(np.shape(y_2)[0],n_samples)\n",
    "    y_test_3 = np.tile(np.array([0., 0., 1.]), \n",
    "                np.shape(y_3)[0]).reshape(np.shape(y_3)[0],n_samples)\n",
    "    y_test = np.concatenate((y_test_1, y_test_2, y_test_3))\n",
    "    indices_test = rng.permutation(np.shape(x_test)[0])\n",
    "    x_test = x_test[indices_test]\n",
    "    y_test = y_test[indices_test]\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    x_train_1 = np.concatenate((sample_1_1_train, sample_1_2_train, sample_1_3_train))\n",
    "    y_train_1 = np.tile(np.array([1., 0., 0.]), \n",
    "                np.shape(x_train_1)[0]).reshape(np.shape(x_train_1)[0],n_samples)\n",
    "    true_label_1 = np.concatenate((true_label_sample_1_1_train, true_label_sample_1_2_train, \n",
    "                                   true_label_sample_1_3_train))\n",
    "    indices_1 = rng.permutation(np.shape(x_train_1)[0])\n",
    "\n",
    "    x_shuffle_1 = x_train_1[indices_1]\n",
    "    y_shuffle_1 = y_train_1[indices_1]\n",
    "    true_label_shuffle_1 = true_label_1[indices_1]\n",
    "\n",
    "    x_train_2 = np.concatenate((sample_2_1_train, sample_2_2_train, sample_2_3_train))\n",
    "    y_train_2 = np.tile(np.array([0., 1., 0.]), \n",
    "                np.shape(x_train_2)[0]).reshape(np.shape(x_train_2)[0],n_samples)\n",
    "    true_label_2 = np.concatenate((true_label_sample_2_1_train, true_label_sample_2_2_train, \n",
    "                                   true_label_sample_2_3_train))\n",
    "    indices_2 = rng.permutation(np.shape(x_train_2)[0])\n",
    "\n",
    "    x_shuffle_2 = x_train_2[indices_2]\n",
    "    y_shuffle_2 = y_train_2[indices_2]\n",
    "    true_label_shuffle_2 = true_label_2[indices_2]\n",
    "\n",
    "    x_train_3 = np.concatenate((sample_3_1_train, sample_3_2_train, sample_3_3_train))\n",
    "    y_train_3 = np.tile(np.array([0., 0., 1.]), \n",
    "                np.shape(x_train_3)[0]).reshape(np.shape(x_train_3)[0],n_samples)\n",
    "    true_label_3 = np.concatenate((true_label_sample_3_1_train, true_label_sample_3_2_train, \n",
    "                                   true_label_sample_3_3_train))\n",
    "    indices_3 = rng.permutation(np.shape(x_train_3)[0])\n",
    "\n",
    "    x_shuffle_3 = x_train_3[indices_3]\n",
    "    y_shuffle_3 = y_train_3[indices_3]\n",
    "    true_label_shuffle_3 = true_label_3[indices_3]\n",
    "\n",
    "    x_train = np.concatenate((x_shuffle_1, x_shuffle_2, x_shuffle_3))\n",
    "    y_train = np.concatenate((y_shuffle_1, y_shuffle_2, y_shuffle_3))\n",
    "    true_label_train = np.concatenate((true_label_shuffle_1, true_label_shuffle_2, true_label_shuffle_3))\n",
    "\n",
    "    #y_train = np.argmax(y_train, axis = 1)\n",
    "    #true_label_train = np.argmax(true_label_train, axis = 1)\n",
    "\n",
    "    indices_train = rng.permutation(np.shape(x_train)[0])\n",
    "\n",
    "    x_train = x_train[indices_train]\n",
    "    y_train = y_train[indices_train]\n",
    "    true_label_train = true_label_train[indices_train]\n",
    "\n",
    "    model = build_model(x_train.shape[1])\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, verbose=1, patience=10)\n",
    "    y_train_1 = y_train\n",
    "    for i in range(1):\n",
    "        history = model.fit(x_train, y_train_1, validation_split = 0.2, epochs=50, batch_size=1024, verbose=1, \n",
    "                        callbacks=[\n",
    "                                  early_stopping,\n",
    "                                   ])\n",
    "        predict = model.predict(x_train)\n",
    "\n",
    "        predict_0 = predict[np.argmax(y_train_1, axis = 1) == 0]\n",
    "        predict_1 = predict[np.argmax(y_train_1, axis = 1) == 1]\n",
    "        predict_2 = predict[np.argmax(y_train_1, axis = 1) == 2]\n",
    "\n",
    "        # Set Axis labels and Title\n",
    "        scale = 1.0\n",
    "        fontsize = 12\n",
    "        offset = 0.1\n",
    "        figure, tax = ternary.figure(scale=scale)\n",
    "\n",
    "        tax.set_title(\"Prediction for mixed samples in training data\", fontsize=fontsize)\n",
    "        tax.left_axis_label(\"Probability of being mixed sample 3\", fontsize=fontsize, offset=offset)\n",
    "        tax.right_axis_label(\"Probability of being mixed sample 2\", fontsize=fontsize, offset=offset)\n",
    "        tax.bottom_axis_label(\"Probability of being mixed sample 1\", fontsize=fontsize, offset=offset)\n",
    "        tax.scatter(predict_0, color = 'blue', marker = 's', s = 9, label=\"True mixed sample 1\")\n",
    "        tax.scatter(predict_1, color = 'red', marker = 'D', s = 9, label=\"True mixed sample 2\")\n",
    "        tax.scatter(predict_2, color = 'green', marker = 'x', s = 9, label=\"True mixed sample 3\")\n",
    "\n",
    "        # Set ticks\n",
    "        tax.ticks(axis='lbr', multiple=0.2, linewidth=1, tick_formats=\"%.1f\")\n",
    "\n",
    "        # Background color\n",
    "        tax.set_background_color(color=\"whitesmoke\", alpha=0.7) # the default, essentially\n",
    "\n",
    "        # Remove default Matplotlib Axes\n",
    "        tax.clear_matplotlib_ticks()\n",
    "        tax.get_axes().axis('off')\n",
    "        tax.legend()\n",
    "        ternary.plt.show()\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "        x = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "        ax[0].plot(x, history.history['loss'], label='Training')\n",
    "        ax[0].plot(x, history.history['val_loss'], label='Validation')\n",
    "\n",
    "        ax[0].legend(frameon=False)\n",
    "        ax[0].set_title(f'model loss')\n",
    "        ax[0].set_xlabel('Epoch')\n",
    "        ax[0].set_ylabel('Loss')\n",
    "\n",
    "        ax[1].plot(x, history.history['accuracy'], label='Training')\n",
    "        ax[1].plot(x, history.history['val_accuracy'], label='Validation')\n",
    "\n",
    "        ax[1].legend(frameon=False)\n",
    "        ax[1].set_title(f'model accuracy')\n",
    "        ax[1].set_xlabel('Epoch')\n",
    "        ax[1].set_ylabel('Accuracy')\n",
    "        plt.show()\n",
    "        predict[np.argmax(predict, axis = 1) == 0] = [1., 0., 0.]\n",
    "        predict[np.argmax(predict, axis = 1) == 1] = [0., 1., 0.]\n",
    "        predict[np.argmax(predict, axis = 1) == 2] = [0., 0., 1.]\n",
    "        y_train_1 = predict\n",
    "    x_train_post_model = model.predict(x_train_kmeans)\n",
    "    spec_model = SpectralClustering(n_clusters=3, assign_labels = 'discretize')\n",
    "    spec_results = spec_model.fit_predict(x_train_post_model)\n",
    "    \n",
    "    model_clustering =  build_model_clustering(x_train_post_model.shape[1])\n",
    "    num_classes = 3\n",
    "    one_hot_spec_results = np.eye(num_classes)[spec_results]\n",
    "    history_2 = model_clustering.fit(x_train_post_model, one_hot_spec_results, epochs = 10)\n",
    "    \n",
    "    x_predict_pre_kmeans = model.predict(x_test[0:10000])\n",
    "    x_predict_post_spec = spec_model.fit_predict(x_predict_pre_kmeans)\n",
    "    predicted_labels = np.argmax(y_test[0:10000], axis = 1)\n",
    "    print(predicted_labels[0:20])\n",
    "    print(x_predict_post_spec[0:20])\n",
    "    conf_matrix_spec = confusion_matrix(predicted_labels, x_predict_post_spec, labels = [0, 1, 2])\n",
    "    print(conf_matrix_spec)\n",
    "    # Step 2: Use Hungarian algorithm for optimal label assignment\n",
    "    row_ind_spec, col_ind_spec = linear_sum_assignment(-conf_matrix_spec)  # Maximize matches\n",
    "    # Step 3: Map predicted labels to desired labels\n",
    "    label_mapping_spec = {row_spec: col_spec for col_spec, row_spec in zip(row_ind_spec, col_ind_spec)}\n",
    "    print(label_mapping_spec)\n",
    "   \n",
    "    final_labels_spec = np.array([label_mapping_spec[label_spec] for label_spec in x_predict_post_spec])\n",
    "    print(final_labels_spec[0:20])\n",
    "    \n",
    "    accuracy_spec = np.mean(final_labels_spec == np.argmax(y_test[0:10000], axis = 1))\n",
    "    print(np.argmax(y_test[0:10000], axis = 1)[0:20])\n",
    "    print(f\"Spectral Clustering accuracy on pure data, {accuracy_spec*100:.2f}%\")\n",
    "    spec_total_accuracy.append(accuracy_spec)\n",
    "    \n",
    "    x_predict_post_ml = np.argmax(model_clustering.predict(x_predict_pre_kmeans), axis = 1)\n",
    "    #Rematching of labels\n",
    "    print(x_predict_post_ml[0:20])\n",
    "    conf_matrix_ml = confusion_matrix(predicted_labels, x_predict_post_ml, labels = [0, 1, 2])\n",
    "    print(conf_matrix_ml)\n",
    "    # Step 2: Use Hungarian algorithm for optimal label assignment\n",
    "    row_ind_ml, col_ind_ml = linear_sum_assignment(-conf_matrix_ml)  # Maximize matches\n",
    "\n",
    "    # Step 3: Map predicted labels to desired labels\n",
    "    label_mapping_ml = {row_ml: col_ml for col_ml, row_ml in zip(row_ind_ml, col_ind_ml)}\n",
    "    print(label_mapping_ml)\n",
    "    \n",
    "    # Apply mapping to reorder labels\n",
    "    final_labels_ml = np.array([label_mapping_ml[label_ml] for label_ml in x_predict_post_ml])\n",
    "    print(final_labels_ml[0:20])\n",
    "    print(predicted_labels[0:20])\n",
    "    accuracy_ml = np.mean(final_labels_ml == np.argmax(y_test[0:10000], axis = 1))\n",
    "    \n",
    "    scale = 1.0\n",
    "    fontsize = 12\n",
    "    offset = 0.1\n",
    "    figure, tax = ternary.figure(scale=scale)\n",
    "\n",
    "    predict_kmeans_0 = x_predict_pre_kmeans[final_labels_ml == 0]\n",
    "    predict_kmeans_1 = x_predict_pre_kmeans[final_labels_ml == 1]\n",
    "    predict_kmeans_2 = x_predict_pre_kmeans[final_labels_ml == 2]\n",
    "    tax.set_title(\"Spectral Clustering classification\", fontsize=fontsize)\n",
    "    tax.left_axis_label(\"Probability of being sample C\", fontsize=fontsize, offset=offset)\n",
    "    tax.right_axis_label(\"Probability of being sample B\", fontsize=fontsize, offset=offset)\n",
    "    tax.bottom_axis_label(\"Probability of being sample A\", fontsize=fontsize, offset=offset)\n",
    "    tax.scatter(predict_kmeans_0, color = 'blue', marker = 's', s = 9, label=\"ML prediction of sample A\")\n",
    "    tax.scatter(predict_kmeans_1, color = 'red', marker = 'D', s = 9, label=\"ML prediction of sample B\")\n",
    "    tax.scatter(predict_kmeans_2, color = 'green', marker = 'x', s = 9, label=\"ML prediction of sample C\")\n",
    "    # Set ticks\n",
    "    tax.ticks(axis='lbr', multiple=0.2, linewidth=1, tick_formats=\"%.1f\")\n",
    "\n",
    "    # Background color\n",
    "    tax.set_background_color(color=\"whitesmoke\", alpha=0.7) # the default, essentially\n",
    "\n",
    "    # Remove default Matplotlib Axes\n",
    "    tax.clear_matplotlib_ticks()\n",
    "    tax.get_axes().axis('off')\n",
    "    tax.legend(loc = 'upper right')\n",
    "    ternary.plt.show()\n",
    "\n",
    "    print(f\"ML accuracy on pure data, {accuracy_ml*100:.2f}%\")\n",
    "    ml_total_accuracy.append(accuracy_ml)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(x_test[0:10000], y_test[0:10000], verbose=0)\n",
    "    print(f\"One-vs-All Test Accuracy on Pure Data: {accuracy * 100:.2f}%\")\n",
    "    max_total_accuracy.append(accuracy)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "747c0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_total_accuracy = np.array(ml_total_accuracy)\n",
    "spec_total_accuracy = np.array(spec_total_accuracy)\n",
    "max_total_accuracy = np.array(max_total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58f953f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7814 0.7791 0.7918 0.7871 0.7827 0.7967 0.7812 0.7895 0.7871 0.7773]\n"
     ]
    }
   ],
   "source": [
    "print(spec_total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d56e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7546 0.7778 0.7864 0.7875 0.779  0.7964 0.7852 0.7923 0.7871 0.7749]\n"
     ]
    }
   ],
   "source": [
    "print(ml_total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe4e9c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7821199999999999 0.011076894871758945\n",
      "0.78539 0.005809208207664783\n",
      "0.8137 0.0041684494\n"
     ]
    }
   ],
   "source": [
    "#First try, dominant case#\n",
    "print(np.mean(ml_total_accuracy), np.std(ml_total_accuracy))\n",
    "print(np.mean(spec_total_accuracy), np.std(spec_total_accuracy))\n",
    "print(np.mean(max_total_accuracy), np.std(max_total_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fd67ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7821199999999999 0.011076894871758945\n",
      "0.78539 0.005809208207664783\n",
      "0.8137 0.0041684494\n"
     ]
    }
   ],
   "source": [
    "#Second run, ambigous cases \n",
    "print(np.mean(ml_total_accuracy), np.std(ml_total_accuracy))\n",
    "print(np.mean(spec_total_accuracy), np.std(spec_total_accuracy))\n",
    "print(np.mean(max_total_accuracy), np.std(max_total_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third run, must fail cases \n",
    "print(np.mean(ml_total_accuracy), np.std(ml_total_accuracy))\n",
    "print(np.mean(spec_total_accuracy), np.std(spec_total_accuracy))\n",
    "print(np.mean(max_total_accuracy), np.std(max_total_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
